{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d8a8c7a",
   "metadata": {},
   "source": [
    "# Alunos\n",
    "\n",
    "Matheus Dos Santos Palheta -22052572 <br>\n",
    "Matheus Silva dos Santos - 22052573 <br>\n",
    "Vinícius Luiz Nunes da Fonseca - 22050031"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30b8ea8",
   "metadata": {},
   "source": [
    "## Tarefa 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c497c7e0",
   "metadata": {},
   "source": [
    "### Saída de instalação do PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ee8edc",
   "metadata": {},
   "source": [
    "A instalação do PostgreSQL foi feita diretamente do site oficial, iclusive dentro do container docker criado! <br>\n",
    "Foi gerado o seguinte log no terminal após a instalação:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb8bd74",
   "metadata": {
    "tags": [
     "collapsed"
    ]
   },
   "source": [
    "```sh\n",
    "Lendo listas de pacotes... Pronto\n",
    "Construindo árvore de dependências... Pronto\n",
    "Lendo informação de estado... Pronto        \n",
    "Os pacotes adicionais seguintes serão instalados:\n",
    "  libcommon-sense-perl libjson-perl libjson-xs-perl libllvm14 libpq5\n",
    "  libtypes-serialiser-perl postgresql-15 postgresql-client-15\n",
    "  postgresql-client-common postgresql-common sysstat\n",
    "Pacotes sugeridos:\n",
    "  postgresql-doc postgresql-doc-15 isag\n",
    "Os NOVOS pacotes a seguir serão instalados:\n",
    "  libcommon-sense-perl libjson-perl libjson-xs-perl libllvm14 libpq5\n",
    "  libtypes-serialiser-perl postgresql postgresql-15 postgresql-client-15\n",
    "  postgresql-client-common postgresql-common sysstat\n",
    "0 pacotes atualizados, 12 pacotes novos instalados, 0 a serem removidos e 1 não atualizados.\n",
    "É preciso baixar 43,9 MB de arquivos.\n",
    "Depois desta operação, 175 MB adicionais de espaço em disco serão usados.\n",
    "Obter:1 http://br.archive.ubuntu.com/ubuntu jammy/main amd64 libjson-perl all 4.04000-1 [81,8 kB]\n",
    "Obter:2 http://apt.postgresql.org/pub/repos/apt jammy-pgdg/main amd64 postgresql-client-common all 250.pgdg22.04+1 [93,2 kB]\n",
    "Obter:3 http://br.archive.ubuntu.com/ubuntu jammy/main amd64 libcommon-sense-perl amd64 3.75-2build1 [21,1 kB]\n",
    "Obter:4 http://br.archive.ubuntu.com/ubuntu jammy/main amd64 libtypes-serialiser-perl all 1.01-1 [11,6 kB]\n",
    "Obter:5 http://br.archive.ubuntu.com/ubuntu jammy/main amd64 libjson-xs-perl amd64 4.030-1build3 [87,2 kB]\n",
    "Obter:6 http://br.archive.ubuntu.com/ubuntu jammy/main amd64 libllvm14 amd64 1:14.0.0-1ubuntu1 [24,0 MB]\n",
    "Obter:7 http://apt.postgresql.org/pub/repos/apt jammy-pgdg/main amd64 postgresql-common all 250.pgdg22.04+1 [239 kB]\n",
    "Obter:8 http://apt.postgresql.org/pub/repos/apt jammy-pgdg/main amd64 libpq5 amd64 15.3-1.pgdg22.04+1 [184 kB]\n",
    "Obter:9 http://apt.postgresql.org/pub/repos/apt jammy-pgdg/main amd64 postgresql-client-15 amd64 15.3-1.pgdg22.04+1 [1.679 kB]\n",
    "Obter:10 http://apt.postgresql.org/pub/repos/apt jammy-pgdg/main amd64 postgresql-15 amd64 15.3-1.pgdg22.04+1 [16,9 MB]\n",
    "Obter:11 http://br.archive.ubuntu.com/ubuntu jammy-updates/main amd64 sysstat amd64 12.5.2-2ubuntu0.1 [487 kB]\n",
    "Obter:12 http://apt.postgresql.org/pub/repos/apt jammy-pgdg/main amd64 postgresql all 15+250.pgdg22.04+1 [68,2 kB]\n",
    "Baixados 43,9 MB em 23s (1.907 kB/s)                                           \n",
    "Pré-configurando pacotes ...\n",
    "A seleccionar pacote anteriormente não seleccionado libjson-perl.\n",
    "(Lendo banco de dados ... 230675 ficheiros e directórios actualmente instalados.)\n",
    "A preparar para desempacotar .../00-libjson-perl_4.04000-1_all.deb ...\n",
    "A descompactar libjson-perl (4.04000-1) ...\n",
    "A seleccionar pacote anteriormente não seleccionado postgresql-client-common.\n",
    "A preparar para desempacotar .../01-postgresql-client-common_250.pgdg22.04+1_all.deb ...\n",
    "A descompactar postgresql-client-common (250.pgdg22.04+1) ...\n",
    "A seleccionar pacote anteriormente não seleccionado postgresql-common.\n",
    "A preparar para desempacotar .../02-postgresql-common_250.pgdg22.04+1_all.deb ...\n",
    "A acrescentar 'desvio de /usr/bin/pg_config para /usr/bin/pg_config.libpq-dev por postgresql-common'\n",
    "A descompactar postgresql-common (250.pgdg22.04+1) ...\n",
    "A seleccionar pacote anteriormente não seleccionado libcommon-sense-perl:amd64.\n",
    "A preparar para desempacotar .../03-libcommon-sense-perl_3.75-2build1_amd64.deb ...\n",
    "A descompactar libcommon-sense-perl:amd64 (3.75-2build1) ...\n",
    "A seleccionar pacote anteriormente não seleccionado libtypes-serialiser-perl.\n",
    "A preparar para desempacotar .../04-libtypes-serialiser-perl_1.01-1_all.deb ...\n",
    "A descompactar libtypes-serialiser-perl (1.01-1) ...\n",
    "A seleccionar pacote anteriormente não seleccionado libjson-xs-perl.\n",
    "A preparar para desempacotar .../05-libjson-xs-perl_4.030-1build3_amd64.deb ...\n",
    "A descompactar libjson-xs-perl (4.030-1build3) ...\n",
    "A seleccionar pacote anteriormente não seleccionado libllvm14:amd64.\n",
    "A preparar para desempacotar .../06-libllvm14_1%3a14.0.0-1ubuntu1_amd64.deb ...\n",
    "A descompactar libllvm14:amd64 (1:14.0.0-1ubuntu1) ...\n",
    "A seleccionar pacote anteriormente não seleccionado libpq5:amd64.\n",
    "A preparar para desempacotar .../07-libpq5_15.3-1.pgdg22.04+1_amd64.deb ...\n",
    "A descompactar libpq5:amd64 (15.3-1.pgdg22.04+1) ...\n",
    "A seleccionar pacote anteriormente não seleccionado postgresql-client-15.\n",
    "A preparar para desempacotar .../08-postgresql-client-15_15.3-1.pgdg22.04+1_amd64.deb ...\n",
    "A descompactar postgresql-client-15 (15.3-1.pgdg22.04+1) ...\n",
    "A seleccionar pacote anteriormente não seleccionado postgresql-15.\n",
    "A preparar para desempacotar .../09-postgresql-15_15.3-1.pgdg22.04+1_amd64.deb ...\n",
    "A descompactar postgresql-15 (15.3-1.pgdg22.04+1) ...\n",
    "A seleccionar pacote anteriormente não seleccionado postgresql.\n",
    "A preparar para desempacotar .../10-postgresql_15+250.pgdg22.04+1_all.deb ...\n",
    "A descompactar postgresql (15+250.pgdg22.04+1) ...\n",
    "A seleccionar pacote anteriormente não seleccionado sysstat.\n",
    "A preparar para desempacotar .../11-sysstat_12.5.2-2ubuntu0.1_amd64.deb ...\n",
    "A descompactar sysstat (12.5.2-2ubuntu0.1) ...\n",
    "Configurando postgresql-client-common (250.pgdg22.04+1) ...\n",
    "Configurando libpq5:amd64 (15.3-1.pgdg22.04+1) ...\n",
    "Configurando libcommon-sense-perl:amd64 (3.75-2build1) ...\n",
    "Configurando postgresql-client-15 (15.3-1.pgdg22.04+1) ...\n",
    "update-alternatives: a usar /usr/share/postgresql/15/man/man1/psql.1.gz para disponibilizar /usr/share/man/man1/psql.1.gz (psql.1.gz) em modo auto\n",
    "Configurando libllvm14:amd64 (1:14.0.0-1ubuntu1) ...\n",
    "Configurando libtypes-serialiser-perl (1.01-1) ...\n",
    "Configurando libjson-perl (4.04000-1) ...\n",
    "Configurando sysstat (12.5.2-2ubuntu0.1) ...\n",
    "\n",
    "Creating config file /etc/default/sysstat with new version\n",
    "update-alternatives: a usar /usr/bin/sar.sysstat para disponibilizar /usr/bin/sar (sar) em modo auto\n",
    "Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-collect.timer → /lib/systemd/system/sysstat-collect.timer.\n",
    "Created symlink /etc/systemd/system/sysstat.service.wants/sysstat-summary.timer → /lib/systemd/system/sysstat-summary.timer.\n",
    "Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service → /lib/systemd/system/sysstat.service.\n",
    "Configurando libjson-xs-perl (4.030-1build3) ...\n",
    "Configurando postgresql-common (250.pgdg22.04+1) ...\n",
    "Adicionando usuário postgres ao grupo ssl-cert\n",
    "\n",
    "Creating config file /etc/postgresql-common/createcluster.conf with new version\n",
    "Building PostgreSQL dictionaries from installed myspell/hunspell packages...\n",
    "  en_us\n",
    "  pt_br\n",
    "Removing obsolete dictionary files:\n",
    "'/etc/apt/trusted.gpg.d/apt.postgresql.org.gpg' -> '/usr/share/postgresql-common/pgdg/apt.postgresql.org.gpg'\n",
    "Created symlink /etc/systemd/system/multi-user.target.wants/postgresql.service → /lib/systemd/system/postgresql.service.\n",
    "Configurando postgresql-15 (15.3-1.pgdg22.04+1) ...\n",
    "Creating new PostgreSQL cluster 15/main ...\n",
    "/usr/lib/postgresql/15/bin/initdb -D /var/lib/postgresql/15/main --auth-local peer --auth-host scram-sha-256 --no-instructions\n",
    "Os arquivos deste sistema de banco de dados pertencerão ao usuário \"postgres\".\n",
    "Esse usuário deve ser o dono do processo do servidor também.\n",
    "\n",
    "O agrupamento de banco de dados será inicializado com configuração regional \"pt_BR.UTF-8\".\n",
    "A codificação padrão do banco de dados foi definida para \"UTF8\".\n",
    "A configuração de busca textual padrão será definida como \"portuguese\".\n",
    "\n",
    "Verificações de páginas de dados estão desabilitadas.\n",
    "\n",
    "alterando permissões no diretório existente /var/lib/postgresql/15/main ... ok\n",
    "criando subdiretórios ... ok\n",
    "selecionando implementação de memória compartilhada dinâmica ... posix\n",
    "selecionando max_connections padrão ... 100\n",
    "selecionando shared_buffers padrão ... 128MB\n",
    "selecionando fuso horário padrão ... America/Manaus\n",
    "criando arquivos de configuração ... ok\n",
    "executando script de inicialização ... ok\n",
    "executando pós-inicialização ... ok\n",
    "sincronizando dados no disco ... ok\n",
    "Configurando postgresql (15+250.pgdg22.04+1) ...\n",
    "A processar 'triggers' para man-db (2.10.2-1) ...\n",
    "A processar 'triggers' para libc-bin (2.35-0ubuntu3.1) ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497e7912",
   "metadata": {},
   "source": [
    "## Tarefa 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d93bafc",
   "metadata": {},
   "source": [
    "### Fase de preparação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32b51cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app\n",
      "/app/tpch\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "\n",
    "%cd tpch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74d459b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc -g -DDBNAME=\\\"dss\\\" -DLINUX -DORACLE -DTPCH -DRNG_TEST -D_FILE_OFFSET_BITS=64   -c -o build.o build.c\n",
      "gcc -g -DDBNAME=\\\"dss\\\" -DLINUX -DORACLE -DTPCH -DRNG_TEST -D_FILE_OFFSET_BITS=64   -c -o driver.o driver.c\n",
      "gcc -g -DDBNAME=\\\"dss\\\" -DLINUX -DORACLE -DTPCH -DRNG_TEST -D_FILE_OFFSET_BITS=64   -c -o bm_utils.o bm_utils.c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bm_utils.c: In function ‘tbl_open’:\n",
      "bm_utils.c:404:51: warning: ‘%s’ directive writing up to 255 bytes into a region of size 231 [-Wformat-overflow=]\n",
      "  404 |         sprintf(prompt, \"Do you want to overwrite %s ?\", fullpath);\n",
      "      |                                                   ^~     ~~~~~~~~\n",
      "bm_utils.c:404:9: note: ‘sprintf’ output between 28 and 283 bytes into a destination of size 256\n",
      "  404 |         sprintf(prompt, \"Do you want to overwrite %s ?\", fullpath);\n",
      "      |         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc -g -DDBNAME=\\\"dss\\\" -DLINUX -DORACLE -DTPCH -DRNG_TEST -D_FILE_OFFSET_BITS=64   -c -o rnd.o rnd.c\n",
      "gcc -g -DDBNAME=\\\"dss\\\" -DLINUX -DORACLE -DTPCH -DRNG_TEST -D_FILE_OFFSET_BITS=64   -c -o print.o print.c\n",
      "gcc -g -DDBNAME=\\\"dss\\\" -DLINUX -DORACLE -DTPCH -DRNG_TEST -D_FILE_OFFSET_BITS=64   -c -o load_stub.o load_stub.c\n",
      "gcc -g -DDBNAME=\\\"dss\\\" -DLINUX -DORACLE -DTPCH -DRNG_TEST -D_FILE_OFFSET_BITS=64   -c -o bcd2.o bcd2.c\n",
      "gcc -g -DDBNAME=\\\"dss\\\" -DLINUX -DORACLE -DTPCH -DRNG_TEST -D_FILE_OFFSET_BITS=64   -c -o speed_seed.o speed_seed.c\n",
      "gcc -g -DDBNAME=\\\"dss\\\" -DLINUX -DORACLE -DTPCH -DRNG_TEST -D_FILE_OFFSET_BITS=64   -c -o text.o text.c\n",
      "gcc -g -DDBNAME=\\\"dss\\\" -DLINUX -DORACLE -DTPCH -DRNG_TEST -D_FILE_OFFSET_BITS=64   -c -o permute.o permute.c\n",
      "gcc -g -DDBNAME=\\\"dss\\\" -DLINUX -DORACLE -DTPCH -DRNG_TEST -D_FILE_OFFSET_BITS=64   -c -o rng64.o rng64.c\n",
      "gcc -g -DDBNAME=\\\"dss\\\" -DLINUX -DORACLE -DTPCH -DRNG_TEST -D_FILE_OFFSET_BITS=64 -O -o dbgen build.o driver.o bm_utils.o rnd.o print.o load_stub.o bcd2.o speed_seed.o text.o permute.o rng64.o -lm\n",
      "gcc -g -DDBNAME=\\\"dss\\\" -DLINUX -DORACLE -DTPCH -DRNG_TEST -D_FILE_OFFSET_BITS=64   -c -o qgen.o qgen.c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In file included from qgen.c:41:\n",
      "qgen.c: In function ‘qsub’:\n",
      "tpcd.h:76:19: warning: zero-length gnu_printf format string [-Wformat-zero-length]\n",
      "   76 | #define SET_DBASE \"\"\n",
      "      |                   ^~\n",
      "qgen.c:197:38: note: in expansion of macro ‘SET_DBASE’\n",
      "  197 |                         fprintf(ofp, SET_DBASE, db_name);\n",
      "      |                                      ^~~~~~~~~\n",
      "TPC-H Population Generator (Version 2.14.0)\n",
      "Copyright Transaction Processing Performance Council 1994 - 2010\n",
      "Generating data for suppliers table/\b\n",
      "Preloading text ...   0%\b\b\b\b  0%\b\b\b\b  0%\b\b\b\b  0%\b\b\b\b  0%\b\b\b\b  0%\b\b\b\b  0%\b\b\b\b  0%\b\b\b\b  1%\b\b\b\b  1%\b\b\b\b  1%\b\b\b\b  1%\b\b\b\b  1%\b\b\b\b  1%\b\b\b\b  1%\b\b\b\b  1%\b\b\b\b  1%\b\b\b\b  1%\b\b\b\b  1%\b\b\b\b  1%\b\b\b\b  1%\b\b\b\b  1%\b\b\b\b  1%\b\b\b\b  1%\b\b\b\b  2%\b\b\b\b  2%\b\b\b\b  2%\b\b\b\b  2%\b\b\b\b  2%\b\b\b\b  2%\b\b\b\b  2%\b\b\b\b  2%\b\b\b\b  2%\b\b\b\b  2%\b\b\b\b  2%\b\b\b\b  2%\b\b\b\b  2%\b\b\b\b  2%\b\b\b\b  2%\b\b\b\b  2%\b\b\b\b  3%\b\b\b\b  3%\b\b\b\b  3%\b\b\b\b  3%\b\b\b\b  3%\b\b\b\b  3%\b\b\b\b  3%\b\b\b\b  3%\b\b\b\b  3%\b\b\b\b  3%\b\b\b\b  3%\b\b\b\b  3%\b\b\b\b  3%\b\b\b\b  3%\b\b\b\b  3%\b\b\b\b  3%\b\b\b\b  4%\b\b\b\b  4%\b\b\b\b  4%\b\b\b\b  4%\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc -g -DDBNAME=\\\"dss\\\" -DLINUX -DORACLE -DTPCH -DRNG_TEST -D_FILE_OFFSET_BITS=64   -c -o varsub.o varsub.c\n",
      "gcc -g -DDBNAME=\\\"dss\\\" -DLINUX -DORACLE -DTPCH -DRNG_TEST -D_FILE_OFFSET_BITS=64 -O -o qgen build.o bm_utils.o qgen.o rnd.o varsub.o text.o bcd2.o permute.o speed_seed.o rng64.o -lm\n",
      "built dbgen from source\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                     1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 91010101010101010\n",
      "done.\n",
      "Generating data for customers tabledone.\n",
      "Generating data for orders/lineitem tablesdone.\n",
      "Generating data for part/partsupplier tablesdone.\n",
      "Generating data for nation tabledone.\n",
      "Generating data for region tabledone.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated data for the load phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPC-H Population Generator (Version 2.14.0)\n",
      "Copyright Transaction Processing Performance Council 1994 - 2010\n",
      "Generating update pair #1 for orders/lineitem tables\n",
      "Preloading text ...                                                                                                                                                                                                                                                                                                              1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 91010101010101010\n",
      "done.\n",
      "Generating update pair #2 for orders/lineitem tablesdone.\n",
      "Generating update pair #3 for orders/lineitem tablesdone.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated data for the update phase\n",
      "generated data for the delete phase\n",
      "created data files in ./data\n",
      "created query files in ./query_root\n"
     ]
    }
   ],
   "source": [
    "%run tpch_pgsql.py prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26e2041",
   "metadata": {},
   "source": [
    "### Fase de carregamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99fb557d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped existing tables\n",
      "cleaned database tpch\n",
      "done creating schemas\n",
      "done loading data to tables\n",
      "done creating indexes and foreign keys\n",
      "============================================================\n",
      "=========================== Load ===========================\n",
      "============================================================\n",
      "create_schema: : 0:00:00.305571\n",
      "load_data: 0:01:03.599249\n",
      "index_tables: 0:00:33.215374\n",
      "============================================================\n",
      "======================= End Results ========================\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "%run tpch_pgsql.py load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29100529",
   "metadata": {},
   "source": [
    "## Tarefa 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85393452",
   "metadata": {},
   "source": [
    "### Execução das consultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63bd0955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power tests started ...\n",
      "Power tests finished.\n",
      "Throughput tests started ...\n",
      "Throughput tests in stream #1 started ...\n",
      "Throughput tests in stream #2 started ...\n",
      "Throughput tests finished.\n",
      "done performance tests\n",
      "Power@Size = 7629.724831135565\n",
      "Throughput@Size = 7217.55933765588\n",
      "QphH@Size = 7420.781070662807\n",
      "============================================================\n",
      "========================= Metrics ==========================\n",
      "============================================================\n",
      "power_size: 7629.724831135565\n",
      "throughput_size: 7217.55933765588\n",
      "qphh_size: 7420.781070662807\n",
      "============================================================\n",
      "======================= End Results ========================\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "%run tpch_pgsql.py query "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7269de",
   "metadata": {},
   "source": [
    "## Tarefa 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78c5ba2",
   "metadata": {},
   "source": [
    "### Informações Sistema Operacional:\n",
    "\n",
    "PRETTY_NAME=\"Ubuntu 22.04.2 LTS\" <br>\n",
    "VERSION=\"22.04.2 LTS (Jammy Jellyfish)\"<br>\n",
    "ID=ubuntu<br>\n",
    "ID_LIKE=debian<br>\n",
    "HOME_URL=\"https://www.ubuntu.com/\"<br>\n",
    "SUPPORT_URL=\"https://help.ubuntu.com/\"<br>\n",
    "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"<br>\n",
    "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"<br>\n",
    "UBUNTU_CODENAME=jammy<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7683be1",
   "metadata": {},
   "source": [
    "### informações CPU\n",
    "Architecture:            x86_64 <br>\n",
    "  Address sizes:         48 bits physical, 48 bits virtual<br>\n",
    "  Byte Order:            Little Endian<br>\n",
    "Vendor ID:               AuthenticAMD<br>\n",
    "  Model name:            AMD Ryzen 5 5600G with Radeon Graphics<br>\n",
    "    CPU family:          25<br>\n",
    "    Model:               80<br>\n",
    "    Thread(s) per core:  2<br>\n",
    "    Core(s) per socket:  6<br>\n",
    "    Socket(s):           1<br>\n",
    "    Stepping:            0<br>\n",
    "    BogoMIPS:            7785.09<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95966847",
   "metadata": {},
   "source": [
    "### Informação memória\n",
    "\n",
    "      total        used        free      shared  buff/cache   available\n",
    "      6.7Gi       671Mi       5.2Gi        16Mi       852Mi       5.8Gi mem\n",
    "      2.0Gi          0B       2.0Gi                                     swap\n",
    "      \n",
    "      Filesystem      Size  Used Avail Use% Mounted on\n",
    "      drvfs           475G  338G  138G  72% /mnt/c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f552348",
   "metadata": {},
   "source": [
    "## Tarefa 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26d5f72",
   "metadata": {},
   "source": [
    "## Tarefa 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091a2200",
   "metadata": {},
   "source": [
    "| Característica                                 | Descrição                                                                                                                                                                                                                          |\n",
    "|-----------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Modelo de Armazenamento                        | O PostgreSQL utiliza o modelo de armazenamento relacional, baseado em tabelas, colunas e linhas, seguindo os princípios do modelo ACID (Atomicidade, Consistência, Isolamento e Durabilidade).                                      |\n",
    "| Formato de Armazenamento                       | O PostgreSQL armazena os dados em páginas de tamanho fixo (geralmente 8 KB por página), onde cada página pode conter várias tuplas. Os dados são organizados em segmentos, tablespaces e bancos de dados.                          |\n",
    "| Controle de Acesso aos Dados                   | O PostgreSQL oferece um sistema de controle de acesso robusto e flexível, permitindo a definição de permissões de acesso a nível de objeto (tabelas, colunas, etc.) e a nível de usuário/grupo.                                     |\n",
    "| Indexação de Dados                             | O PostgreSQL suporta vários tipos de índices, incluindo índices B-tree, hash, GIN (Generalized Inverted Index) e GiST (Generalized Search Tree), permitindo a otimização do acesso aos dados em diferentes cenários.               |\n",
    "| Compressão de Dados                            | O PostgreSQL oferece suporte à compressão de dados por meio de técnicas como TOAST (The Oversized-Attribute Storage Technique) e tabelas particionadas, permitindo economia de espaço de armazenamento.                             |\n",
    "| Gerenciamento de Espaço em Disco               | O PostgreSQL utiliza um sistema de gerenciamento de espaço em disco que aloca automaticamente espaço para novos dados e realiza reutilização de espaço para dados removidos ou atualizados.                                         |\n",
    "| Recuperação de Falhas (Recovery)               | O PostgreSQL possui um mecanismo de recuperação robusto, com suporte a logs de transação (WAL - Write-Ahead Logging) que permite a recuperação do banco de dados para um estado consistente após uma falha.                         |\n",
    "| Replicação de Dados                            | O PostgreSQL oferece várias opções de replicação de dados, incluindo replicação baseada em registros (Streaming Replication), replicação síncrona e assíncrona, permitindo alta disponibilidade e escalabilidade.                      |\n",
    "| Particionamento de Tabelas                     | O PostgreSQL suporta o particionamento de tabelas, permitindo que grandes conjuntos de dados sejam divididos em partições menores com base em um critério especificado, o que facilita o gerenciamento de grandes volumes de dados. |\n",
    "| Recursos Avançados de Consulta e Otimização    | O PostgreSQL possui um otimizador de consultas avançado que analisa as consultas submetidas e escolhe o plano de execução mais eficiente. Além disso, oferece recursos como estatísticas de tabelas, views materializadas e otimização de expressões.  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a5f9cd",
   "metadata": {},
   "source": [
    "## Tarefa 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfba233",
   "metadata": {},
   "source": [
    "| Sistema de Arquivo | Descrição | Capacidade Máxima de Arquivo | Capacidade Máxima de Sistema de Arquivo | Journaling | Fragmentação | Suporte a ACLs | Compressão | Transações |\n",
    "|--------------------|-----------|------------------------------|---------------------------------------|------------|--------------|----------------|------------|------------|\n",
    "| Ext2               | O Ext2 é um sistema de arquivos de primeira geração para o Linux. | 2 TB | 4 TB | Não | Propenso à fragmentação | Não | Não | Não |\n",
    "| Ext3               | O Ext3 é uma extensão do Ext2 que adiciona journaling para maior segurança. | 2 TB | 4 TB | Sim | Propenso à fragmentação | Não | Não | Não |\n",
    "| ReiserFS           | O ReiserFS é um sistema de arquivos de alto desempenho, conhecido por sua rápida manipulação de pequenos arquivos. | 8 TB | 16 TB | Sim | Melhor desempenho com arquivos pequenos | Sim | Não | Não |\n",
    "| XFS                | O XFS é um sistema de arquivos de alto desempenho, otimizado para escalabilidade e grandes sistemas de armazenamento. | 8 EB | 8 EB | Sim | Melhor desempenho com arquivos grandes | Sim | Sim | Sim |\n",
    "\n",
    "Observações:\n",
    "\n",
    "    Capacidade máxima de arquivo refere-se ao tamanho máximo de um único arquivo suportado pelo sistema de arquivos.\n",
    "    Capacidade máxima de sistema de arquivos refere-se ao tamanho máximo total do sistema de arquivos.\n",
    "    Journaling refere-se à técnica de registro de transações para garantir a consistência dos dados após falhas de energia ou reinicializações inesperadas.\n",
    "    Fragmentação indica a tendência do sistema de arquivos em fragmentar os arquivos em várias partes físicas do disco.\n",
    "    ACLs (Access Control Lists) permitem a atribuição de permissões mais granulares a arquivos e diretórios.\n",
    "    Compressão indica se o sistema de arquivos suporta compressão de dados para economizar espaço de armazenamento.\n",
    "    Transações referem-se à capacidade do sistema de arquivos de executar operações atômicas (tudo ou nada)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dab85c6",
   "metadata": {},
   "source": [
    "## Tarefa 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efba4e14",
   "metadata": {},
   "source": [
    "## Tarefa 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf008e2",
   "metadata": {},
   "source": [
    "## Tarefa 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac2c73a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexão estabelecida com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import time\n",
    "\n",
    "# Parâmetros de conexão\n",
    "DEFAULT_HOST = \"localhost\"\n",
    "DEFAULT_PORT = 5432\n",
    "DEFAULT_USERNAME = \"postgres\"\n",
    "DEFAULT_PASSWORD = \"postgres\"\n",
    "DEFAULT_DBNAME = \"series\"\n",
    "\n",
    "# Estabelecer conexão com o PostgreSQL\n",
    "conn = psycopg2.connect(\n",
    "    host=DEFAULT_HOST,\n",
    "    port=DEFAULT_PORT,\n",
    "    user=DEFAULT_USERNAME,\n",
    "    password=DEFAULT_PASSWORD,\n",
    "    database=DEFAULT_DBNAME\n",
    ")\n",
    "print(\"Conexão estabelecida com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77dfdfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela populada com sucesso!\n",
      "k = 1 v = 5\n",
      "k = 2 v = 1\n",
      "k = 3 v = 7\n",
      "k = 4 v = 5\n",
      "k = 5 v = 6\n",
      "k = 6 v = 2\n",
      "k = 7 v = 8\n",
      "k = 8 v = 8\n",
      "k = 9 v = 1\n",
      "k = 10 v = 0\n"
     ]
    }
   ],
   "source": [
    "# Popular a tabela \"t\"\n",
    "create_table_query = \"\"\"\n",
    "DROP TABLE IF EXISTS t;\n",
    "CREATE TABLE t (k serial PRIMARY KEY, v integer);\n",
    "\n",
    "INSERT INTO t(v) \n",
    "SELECT trunc(random() * 10) FROM generate_series(1, 100000);\n",
    "\"\"\"\n",
    "with conn.cursor() as cursor:\n",
    "    cursor.execute(create_table_query)\n",
    "connection.commit()\n",
    "print(\"Tabela populada com sucesso!\")\n",
    "\n",
    "# Executar a consulta SQL para obter os valores das 10 primeiras tuplas ordenadas por \"k\"\n",
    "select_query = \"\"\"\n",
    "SELECT * FROM t ORDER BY k LIMIT 10;\n",
    "\"\"\"\n",
    "with conn.cursor() as cursor:\n",
    "    cursor.execute(select_query)\n",
    "    rows = cursor.fetchall()\n",
    "    for row in rows:\n",
    "        print(f\"k = {row[0]} v = {row[1]}\")\n",
    "\n",
    "# Fechar cursor\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63c1116",
   "metadata": {},
   "source": [
    "## Tarefa 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a17113a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table:  t\n",
      "Number of pages:  443\n",
      "Number of tuples:  100000.0\n"
     ]
    }
   ],
   "source": [
    "# Criar cursor\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Atualizar as estatísticas da tabela 't'\n",
    "cursor.execute(\"ANALYZE t\")\n",
    "\n",
    "# Executar a consulta\n",
    "cursor.execute(\"SELECT relname, relpages, reltuples FROM pg_class WHERE relname='t';\")\n",
    "\n",
    "# Obter o resultado da consulta\n",
    "result = cursor.fetchone()\n",
    "\n",
    "# Imprimir o resultado\n",
    "print(\"Table: \", result[0])\n",
    "print(\"Number of pages: \", result[1])\n",
    "print(\"Number of tuples: \", result[2])\n",
    "\n",
    "# Fechar cursor\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a8dcf9",
   "metadata": {},
   "source": [
    "## Tarefa 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e0f1875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Limit  (cost=0.29..0.60 rows=10 width=8) (actual time=0.005..0.007 rows=10 loops=1)',)\n",
      "('  Buffers: shared hit=3',)\n",
      "('  ->  Index Scan using t_pkey on t  (cost=0.29..3050.29 rows=100000 width=8) (actual time=0.005..0.006 rows=10 loops=1)',)\n",
      "('        Buffers: shared hit=3',)\n",
      "('Planning:',)\n",
      "('  Buffers: shared hit=11',)\n",
      "('Planning Time: 0.037 ms',)\n",
      "('Execution Time: 0.011 ms',)\n"
     ]
    }
   ],
   "source": [
    "# Criar cursor\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Executar os comandos separadamente\n",
    "cursor.execute(\"SELECT pg_sleep(1)\")\n",
    "cursor.execute(\"SELECT * FROM pg_stats WHERE tablename='t'\")\n",
    "cursor.execute(\"SELECT pg_stat_reset()\")\n",
    "cursor.execute(\"EXPLAIN (ANALYZE, BUFFERS) SELECT * FROM t ORDER BY k LIMIT 10\")\n",
    "\n",
    "# Obter o resultado da consulta\n",
    "result = cursor.fetchall()\n",
    "\n",
    "# Imprimir o resultado\n",
    "for row in result:\n",
    "    print(row)\n",
    "\n",
    "# Fechar cursor\n",
    "cursor.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887bb856",
   "metadata": {},
   "source": [
    "## Tarefa 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e66b67",
   "metadata": {},
   "source": [
    "### Qual o tempo gasto para realizar uma consulta para um valor (tendo a tabela 100000 tuplas)?\n",
    "### Qual o tempo gasto para recriar um índice para o atributo ‘v’?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c2362e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo gasto para realizar a consulta: 0.004148960113525391 segundos\n",
      "Tempo gasto para recriar o índice: 0.038358211517333984 segundos\n"
     ]
    }
   ],
   "source": [
    "# Criar cursor\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Criar índice para o atributo 'v'\n",
    "cursor.execute(\"CREATE INDEX idx_v ON t (v)\")\n",
    "\n",
    "# Realizar consulta para um valor específico\n",
    "start_time = time.time()\n",
    "\n",
    "valor_consulta = 5\n",
    "cursor.execute(\"SELECT * FROM t WHERE v = %s\", (valor_consulta,))\n",
    "result = cursor.fetchall()\n",
    "\n",
    "end_time = time.time()\n",
    "consulta_time = end_time - start_time\n",
    "\n",
    "# Medir o tempo gasto para recriar o índice\n",
    "start_time = time.time()\n",
    "\n",
    "cursor.execute(\"DROP INDEX idx_v\")\n",
    "cursor.execute(\"CREATE INDEX idx_v ON t (v)\")\n",
    "\n",
    "end_time = time.time()\n",
    "recriar_indice_time = end_time - start_time\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"Tempo gasto para realizar a consulta: {} segundos\".format(consulta_time))\n",
    "print(\"Tempo gasto para recriar o índice: {} segundos\".format(recriar_indice_time))\n",
    "\n",
    "# Fechar cursor e conexão\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2780ae",
   "metadata": {},
   "source": [
    "### Remova a tabela ‘t’ e crie novamente com 1.0000.000 de tuplas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2cb509e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela recriada com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Criar cursor\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Remover a tabela 't' se existir\n",
    "cursor.execute(\"DROP TABLE IF EXISTS t\")\n",
    "\n",
    "# Criar novamente a tabela 't' com 1.000.000 de tuplas\n",
    "cursor.execute(\"CREATE TABLE t (k serial PRIMARY KEY, v integer)\")\n",
    "\n",
    "# Inserir 1.000.000 de tuplas na tabela\n",
    "cursor.execute(\"INSERT INTO t(v) SELECT trunc(random() * 10) FROM generate_series(1, 1000000)\")\n",
    "\n",
    "# Confirmar as alterações\n",
    "conn.commit()\n",
    "\n",
    "# Fechar cursor\n",
    "cursor.close()\n",
    "print(\"Tabela recriada com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94507142",
   "metadata": {},
   "source": [
    "### Qual o tempo gasto para realizar uma consulta para um valor específico?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a77e5d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consulta retornou 100173 tuplas.\n",
      "Tempo de execução: 0.0612 segundos.\n"
     ]
    }
   ],
   "source": [
    "# Valor específico a ser consultado\n",
    "specific_value = 5\n",
    "\n",
    "# Criar cursor\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Medir o tempo de execução da consulta\n",
    "start_time = time.time()\n",
    "\n",
    "# Executar a consulta\n",
    "cursor.execute(\"SELECT * FROM t WHERE v = %s\", (specific_value,))\n",
    "\n",
    "# Obter o resultado da consulta\n",
    "result = cursor.fetchall()\n",
    "\n",
    "# Calcular o tempo de execução\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Imprimir o resultado e o tempo de execução\n",
    "print(\"Consulta retornou {} tuplas.\".format(len(result)))\n",
    "print(\"Tempo de execução: {:.4f} segundos.\".format(execution_time))\n",
    "\n",
    "# Fechar cursor\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc92359",
   "metadata": {},
   "source": [
    "### Qual o tempo gasto para recriar um índice para o atributo ‘v’?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2432c05a",
   "metadata": {},
   "outputs": [
    {
     "ename": "InterfaceError",
     "evalue": "connection already closed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInterfaceError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Criar cursor\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m cursor \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcursor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Medir o tempo de execução da criação do índice\u001b[39;00m\n\u001b[1;32m      5\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[0;31mInterfaceError\u001b[0m: connection already closed"
     ]
    }
   ],
   "source": [
    "# Criar cursor\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Medir o tempo de execução da criação do índice\n",
    "start_time = time.time()\n",
    "\n",
    "# Recriar o índice para o atributo 'v'\n",
    "cursor.execute(\"DROP INDEX IF EXISTS idx_v\")\n",
    "cursor.execute(\"CREATE INDEX idx_v ON t(v)\")\n",
    "\n",
    "# Calcular o tempo de execução\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "# Imprimir o tempo de execução\n",
    "print(\"Tempo de execução para recriar o índice: {:.4f} segundos.\".format(execution_time))\n",
    "\n",
    "# Fechar cursor\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d59f97b",
   "metadata": {},
   "source": [
    "## Tarefa 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d427645c",
   "metadata": {},
   "source": [
    "### 100000 tuplas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b0d18439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela 't' criada e populada com sucesso!\n",
      "\n",
      "Índice: t_fillfactor_60\n",
      "  Tempo de execução: 0.182..1.404 segundos\n",
      "  Quantidade de linhas retornadas: 500\n",
      "\n",
      "Índice: t_fillfactor_80\n",
      "  Tempo de execução: 0.160..1.046 segundos\n",
      "  Quantidade de linhas retornadas: 500\n",
      "\n",
      "Índice: t_fillfactor_90\n",
      "  Tempo de execução: 0.155..0.940 segundos\n",
      "  Quantidade de linhas retornadas: 500\n",
      "\n",
      "Índice: t_fillfactor_100\n",
      "  Tempo de execução: 0.150..0.896 segundos\n",
      "  Quantidade de linhas retornadas: 500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Estabelecer conexão com o PostgreSQL\n",
    "connection = psycopg2.connect(\n",
    "    host=DEFAULT_HOST,\n",
    "    port=DEFAULT_PORT,\n",
    "    user=DEFAULT_USERNAME,\n",
    "    password=DEFAULT_PASSWORD,\n",
    "    database=DEFAULT_DBNAME\n",
    ")\n",
    "\n",
    "# Criar a tabela \"t\" e popula com os dados necessários\n",
    "create_table_query = \"\"\"\n",
    "DROP TABLE IF EXISTS t;\n",
    "CREATE TABLE t (k serial PRIMARY KEY, v integer);\n",
    "INSERT INTO t (v)\n",
    "SELECT trunc(random() * 10) FROM generate_series(1, 100000);\n",
    "\"\"\"\n",
    "with connection.cursor() as cursor:\n",
    "    cursor.execute(create_table_query)\n",
    "connection.commit()\n",
    "print(\"Tabela 't' criada e populada com sucesso!\\n\")\n",
    "\n",
    "# Criar índices na tabela \"t\" com diferentes valores de fillfactor\n",
    "fillfactors = [60, 80, 90, 100]\n",
    "for fillfactor in fillfactors:\n",
    "    index_name = f\"t_fillfactor_{fillfactor}\"\n",
    "    create_index_query = f\"\"\"\n",
    "    CREATE INDEX {index_name} ON t (v) WITH (fillfactor={fillfactor});\n",
    "    \"\"\"\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(create_index_query)\n",
    "    connection.commit()\n",
    "\n",
    "# Executar as consultas e analisar o desempenho\n",
    "select_query = \"\"\"\n",
    "SELECT * FROM t WHERE v = 5;\n",
    "\"\"\"\n",
    "for fillfactor in fillfactors:\n",
    "    index_name = f\"t_fillfactor_{fillfactor}\"\n",
    "    explain_query = f\"EXPLAIN (ANALYZE, BUFFERS) {select_query}\"\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(explain_query)\n",
    "        result = cursor.fetchone()\n",
    "        print(f\"Índice: {index_name}\")\n",
    "        execution_time = result[0].split(\"actual time=\")[1].split(\" \")[0]\n",
    "        print(f\"  Tempo de execução: {execution_time} segundos\")\n",
    "        print(f\"  Quantidade de linhas retornadas: {result[0].split('rows=')[1].split(' ')[0]}\")\n",
    "        print()\n",
    "\n",
    "# Fechar a conexão\n",
    "connection.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2df3036",
   "metadata": {},
   "source": [
    "### 1000000 tuplas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8b8c99aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela 't' criada e populada com sucesso!\n",
      "\n",
      "Índice: t_fillfactor_60\n",
      "  Tempo de execução: 2.112..14.174 segundos\n",
      "  Quantidade de linhas retornadas: 5000\n",
      "\n",
      "Índice: t_fillfactor_80\n",
      "  Tempo de execução: 2.011..13.671 segundos\n",
      "  Quantidade de linhas retornadas: 5000\n",
      "\n",
      "Índice: t_fillfactor_90\n",
      "  Tempo de execução: 1.938..13.337 segundos\n",
      "  Quantidade de linhas retornadas: 5000\n",
      "\n",
      "Índice: t_fillfactor_100\n",
      "  Tempo de execução: 1.907..13.172 segundos\n",
      "  Quantidade de linhas retornadas: 5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Estabelecer conexão com o PostgreSQL\n",
    "connection = psycopg2.connect(\n",
    "    host=DEFAULT_HOST,\n",
    "    port=DEFAULT_PORT,\n",
    "    user=DEFAULT_USERNAME,\n",
    "    password=DEFAULT_PASSWORD,\n",
    "    database=DEFAULT_DBNAME\n",
    ")\n",
    "\n",
    "# Criar a tabela \"t\" e popula com os dados necessários\n",
    "create_table_query = \"\"\"\n",
    "DROP TABLE IF EXISTS t;\n",
    "CREATE TABLE t (k serial PRIMARY KEY, v integer);\n",
    "INSERT INTO t (v)\n",
    "SELECT trunc(random() * 10) FROM generate_series(1, 1000000);\n",
    "\"\"\"\n",
    "with connection.cursor() as cursor:\n",
    "    cursor.execute(create_table_query)\n",
    "connection.commit()\n",
    "print(\"Tabela 't' criada e populada com sucesso!\\n\")\n",
    "\n",
    "# Criar índices na tabela \"t\" com diferentes valores de fillfactor\n",
    "fillfactors = [60, 80, 90, 100]\n",
    "for fillfactor in fillfactors:\n",
    "    index_name = f\"t_fillfactor_{fillfactor}\"\n",
    "    create_index_query = f\"\"\"\n",
    "    CREATE INDEX {index_name} ON t (v) WITH (fillfactor={fillfactor});\n",
    "    \"\"\"\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(create_index_query)\n",
    "    connection.commit()\n",
    "\n",
    "# Executar as consultas e analisar o desempenho\n",
    "select_query = \"\"\"\n",
    "SELECT * FROM t WHERE v = 5;\n",
    "\"\"\"\n",
    "for fillfactor in fillfactors:\n",
    "    index_name = f\"t_fillfactor_{fillfactor}\"\n",
    "    explain_query = f\"EXPLAIN (ANALYZE, BUFFERS) {select_query}\"\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(explain_query)\n",
    "        result = cursor.fetchone()\n",
    "        print(f\"Índice: {index_name}\")\n",
    "        execution_time = result[0].split(\"actual time=\")[1].split(\" \")[0]\n",
    "        print(f\"  Tempo de execução: {execution_time} segundos\")\n",
    "        print(f\"  Quantidade de linhas retornadas: {result[0].split('rows=')[1].split(' ')[0]}\")\n",
    "        print()\n",
    "\n",
    "# Fechar a conexão\n",
    "connection.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087247e3",
   "metadata": {},
   "source": [
    "## Tarefa 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2916e4",
   "metadata": {},
   "source": [
    "## Tarefa 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06ce0d1",
   "metadata": {},
   "source": [
    "## Tarefa 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cc6ec7",
   "metadata": {},
   "source": [
    "## Tarefa 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a88645",
   "metadata": {},
   "source": [
    "## Tarefa 19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979fdf0a",
   "metadata": {},
   "source": [
    "## Tarefa 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f66fedb",
   "metadata": {},
   "source": [
    "## Tarefa 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd02932c",
   "metadata": {},
   "source": [
    "## Tarefa 22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a61dae6",
   "metadata": {},
   "source": [
    "## Tarefa 23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a78af7",
   "metadata": {},
   "source": [
    "## Tarefa 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7dff2c",
   "metadata": {},
   "source": [
    "## Tarefa 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ee395f",
   "metadata": {},
   "source": [
    "## Tarefa 26"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
